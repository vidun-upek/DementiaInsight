{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e736534c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5715338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (156156, 8)\n",
      "y_train shape: (156156,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the data saved from the EDA notebook\n",
    "data_dir = '../data/processed'\n",
    "\n",
    "X_train = pd.read_csv(f'{data_dir}/X_train.csv')\n",
    "X_test = pd.read_csv(f'{data_dir}/X_test.csv')\n",
    "y_train = pd.read_csv(f'{data_dir}/y_train.csv').squeeze() # squeeze() turns to Series\n",
    "y_test = pd.read_csv(f'{data_dir}/y_test.csv').squeeze()\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9453d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on our Data Dictionary exploration [cite: 1547, 1885, 2612, 1893, 1904]\n",
    "\n",
    "# Numerical features: These will be imputed (with the median) and scaled.\n",
    "numerical_features = ['NACCAGE', 'EDUC', 'SMOKYRS']\n",
    "\n",
    "# Categorical features: These will be imputed (with the most frequent value) \n",
    "categorical_features = ['TOBAC30', 'ALCOCCAS', 'ALCFREQ', 'MARISTAT', 'NACCLIVS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494ee70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREATE PREPROCESSING PIPELINES \n",
    "\n",
    "def to_numeric(df):\n",
    "    # na_values from 01_eda.ipynb\n",
    "    na_values = [-4, 9, 88, 99, 888, 999, 9999] \n",
    "    # Coerce errors will turn any remaining text (like 'missing') into NaN\n",
    "    return df.apply(pd.to_numeric, errors='coerce').replace(na_values, np.nan)\n",
    "\n",
    "#  A helper function to force columns to string (for categories)\n",
    "# This will fix the 'cannot cast str to int64' error.\n",
    "def to_string(df):\n",
    "    return df.astype(str)\n",
    "\n",
    "\n",
    "# Pipeline for numerical data\n",
    "numeric_transformer = Pipeline(steps=[\n",
    " \n",
    "    ('to_numeric', FunctionTransformer(to_numeric, feature_names_out='one-to-one')), \n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "\n",
    "    ('to_string', FunctionTransformer(to_string, feature_names_out='one-to-one')),\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e3503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE THE COLUMN TRANSFORMER \n",
    "# This object applies the correct pipeline to the correct columns\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d2fa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying preprocessor to training data...\n",
      "Applying preprocessor to test data...\n",
      "X_train_processed shape: (156156, 32)\n",
      "X_test_processed shape: (39040, 32)\n"
     ]
    }
   ],
   "source": [
    "# FIT AND TRANSFORM THE DATA \n",
    "\n",
    "print(\"Applying preprocessor to training data...\")\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "print(\"Applying preprocessor to test data...\")\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "print(f\"X_train_processed shape: {X_train_processed.shape}\")\n",
    "print(f\"X_test_processed shape: {X_test_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e28b7b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Feature Names:\n",
      "['NACCAGE', 'EDUC', 'SMOKYRS', 'TOBAC30_-4', 'TOBAC30_0', 'TOBAC30_1', 'TOBAC30_9', 'ALCOCCAS_-4', 'ALCOCCAS_0', 'ALCOCCAS_1', 'ALCOCCAS_9', 'ALCFREQ_-4', 'ALCFREQ_0', 'ALCFREQ_1', 'ALCFREQ_2', 'ALCFREQ_3', 'ALCFREQ_4', 'ALCFREQ_8', 'ALCFREQ_9', 'MARISTAT_1', 'MARISTAT_2', 'MARISTAT_3', 'MARISTAT_4', 'MARISTAT_5', 'MARISTAT_6', 'MARISTAT_9', 'NACCLIVS_1', 'NACCLIVS_2', 'NACCLIVS_3', 'NACCLIVS_4', 'NACCLIVS_5', 'NACCLIVS_9']\n"
     ]
    }
   ],
   "source": [
    "# Get the new feature names created by the OneHotEncoder\n",
    "feature_names = preprocessor.get_feature_names_out()\n",
    "\n",
    "# Clean up the names (e.g., remove \"num__\" and \"cat__\" prefixes)\n",
    "clean_feature_names = [name.split('__')[-1] for name in feature_names]\n",
    "\n",
    "print(\"Processed Feature Names:\")\n",
    "print(clean_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80e8133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data and artifacts saved to ../data/processed\n"
     ]
    }
   ],
   "source": [
    "# SAVE PROCESSED DATA FOR MODELING\n",
    "# We will save the processed arrays and the feature names list\n",
    "\n",
    "processed_dir = '../data/processed'\n",
    "\n",
    "# Save the processed numpy arrays\n",
    "np.save(f'{processed_dir}/X_train_processed.npy', X_train_processed)\n",
    "np.save(f'{processed_dir}/X_test_processed.npy', X_test_processed)\n",
    "\n",
    "# Save the target variables \n",
    "y_train.to_csv(f'{processed_dir}/y_train.csv', index=False)\n",
    "y_test.to_csv(f'{processed_dir}/y_test.csv', index=False)\n",
    "\n",
    "# Save the preprocessor itself and the feature names \n",
    "with open(f'{processed_dir}/preprocessor.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessor, f)\n",
    "    \n",
    "with open(f'{processed_dir}/feature_names.pkl', 'wb') as f:\n",
    "    pickle.dump(clean_feature_names, f)\n",
    "\n",
    "print(f\"Processed data and artifacts saved to {processed_dir}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
